# ğŸ¦ OpenClaw DeepReader

> **The default web content gateway for OpenClaw agents.** Read X (Twitter), Reddit, YouTube, and any webpage â€” zero config, zero API keys.

DeepReader is the built-in content reader for the [OpenClaw](https://github.com/anthropics/openclaw) agent framework. Paste any URL into a conversation, and DeepReader automatically fetches, parses, and saves high-quality Markdown to your agent's long-term memory. Built for social media and the modern web.

ğŸŒ **Translations**: [ä¸­æ–‡](README_zh.md) Â· [EspaÃ±ol](README_es.md) Â· [í•œêµ­ì–´](README_ko.md) Â· [æ—¥æœ¬èª](README_ja.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_ar.md) Â· [FranÃ§ais](README_fr.md)

---

## âš¡ Install

```bash
npx clawhub@latest install deepreader
```

Or install manually:

```bash
git clone https://github.com/astonysh/OpenClaw-DeepReeder.git
cd OpenClaw-DeepReeder
python3 -m venv .venv && source .venv/bin/activate
pip install -e .
```

---

## ğŸ¯ Use When

- You need to **read a tweet, thread, or X article** and add it to OpenClaw's memory
- You need to **ingest a Reddit post** with top comments and discussion context
- You want to **save a YouTube transcript** for later reference or analysis
- You want to **clip any blog, article, or documentation page** into clean Markdown
- Your agent needs a **default web reader** that just works â€” no API keys, no setup

---

## âœ¨ Supported Sources

| Parser | Sources | Method | API Key? |
|--------|---------|--------|----------|
| ğŸ¦ **Twitter / X** | Tweets, threads, X Articles | [FxTwitter API](https://github.com/FxEmbed/FxEmbed) + Nitter fallback | âŒ None |
| ğŸŸ  **Reddit** | Posts + comment threads | Reddit `.json` API | âŒ None |
| ğŸ¬ **YouTube** | Video transcripts | [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) | âŒ None |
| ğŸŒ **Any URL** | Blogs, articles, docs | [Trafilatura](https://trafilatura.readthedocs.io/) + BeautifulSoup | âŒ None |

**Zero API keys. Zero login. Zero rate limits. Just paste and read.**

---

## ğŸ¦ Twitter / X â€” Deep Integration

Powered by [FxTwitter](https://github.com/FxEmbed/FxEmbed) API with Nitter fallback. Inspired by [x-tweet-fetcher](https://github.com/ythx-101/x-tweet-fetcher).

| Content Type | Support |
|-------------|---------|
| Regular tweets | âœ… Full text + engagement stats |
| Long tweets (Twitter Blue) | âœ… Full text |
| X Articles (long-form) | âœ… Complete article text + word count |
| Quoted tweets | âœ… Nested content included |
| Media (images, video, GIF) | âœ… URLs extracted |
| Reply threads | âœ… Via Nitter fallback (first 5) |
| Engagement stats | âœ… â¤ï¸ likes, ğŸ” RTs, ğŸ‘ï¸ views, ğŸ”– bookmarks |

## ğŸŸ  Reddit â€” Native JSON Integration

Uses Reddit's built-in `.json` URL suffix â€” **no API keys, no OAuth, no registration**.

| Content Type | Support |
|-------------|---------|
| Self posts (text) | âœ… Full markdown body |
| Link posts | âœ… URL + metadata |
| Top comments (sorted by score) | âœ… Up to 15 comments |
| Nested reply threads | âœ… Up to 3 levels deep |
| Media (images, galleries, video) | âœ… URLs extracted |
| Post stats | âœ… â¬†ï¸ score, ğŸ’¬ comment count, upvote ratio |
| Flair tags | âœ… Included |

---

## ğŸš€ Quick Start

```python
from deepreader_skill import run

# Read a tweet â†’ saves to agent memory
result = run("Check out this tweet: https://x.com/elonmusk/status/123456")

# Read a Reddit discussion â†’ captures post + top comments
result = run("Great thread: https://www.reddit.com/r/python/comments/abc123/my_post/")

# Read a YouTube video â†’ saves full transcript
result = run("Watch this: https://youtube.com/watch?v=dQw4w9WgXcQ")

# Read any article â†’ extracts clean content
result = run("Interesting read: https://example.com/blog/ai-agents-2026")

# Batch process multiple URLs at once
result = run("""
  Here are some links to read:
  https://x.com/user/status/123456
  https://www.reddit.com/r/MachineLearning/comments/xyz789/new_paper/
  https://youtube.com/watch?v=dQw4w9WgXcQ
  https://example.com/article
""")
```

---

## ğŸ““ NotebookLM & Audio Integration

DeepReader now seamlessly integrates with **Google NotebookLM**. 

Use explicit flags to opt in:
- `--notebooklm` (or `/notebooklm`) â†’ upload to NotebookLM
- `--audio` / `--podcast` (or `/audio`) â†’ upload + generate Audio Overview

When these flags are present, DeepReader will:
1. Parse the requested URLs into Markdown.
2. Create a new Notebook in your Google NotebookLM account.
3. Upload the Markdown content as a source.
4. **(Optional)** Generate an Audio Overview and download it to the memory folder.

**Supported NotebookLM Artifacts Generation:**
Along with Audio Overviews, this integration can easily be extended to automatically generate and save:
- **ğŸ™ï¸ Audio Overview** (Podcast)
- **ğŸ¥ Video Overview**
- **ğŸ§  Mind Map**
- **ğŸ“„ Reports**
- **ğŸ“‡ Flashcards**
- **â“ Quiz**
- **ğŸ“Š Infographic**
- **ğŸ–¥ï¸ Slide Deck**
- **ğŸ“ˆ Data Table**

> **âš ï¸ Note: Authentication Required**
> Before using the NotebookLM integration, you must authenticate in your terminal (this only needs to be done once):
> ```bash
> notebooklm login
> ```

---

## ğŸ“„ Output Format

Every piece of content is saved as a `.md` file with structured YAML frontmatter:

```yaml
---
title: "[r/python] How I built an AI agent framework"
source_url: "https://www.reddit.com/r/python/comments/abc123/..."
domain: "reddit.com"
parser: "reddit"
ingested_at: "2026-02-16T12:00:00Z"
content_hash: "sha256:abc123..."
word_count: 2500
---

# How I built an AI agent framework

**r/python** Â· u/developer123 Â· 2026-02-16 12:00 UTC
ğŸ“Š â¬†ï¸ 847 (96% upvoted) Â· ğŸ’¬ 234 comments Â· ğŸ·ï¸ Discussion

---

Post body goes here...

---
### ğŸ’¬ Top Comments

**u/expert_dev** (â¬†ï¸ 342):
> This is a really well-structured approach...
```

---

## ğŸ—ï¸ Architecture

```
deepreader_skill/
â”œâ”€â”€ __init__.py          # Entry point â€” run() function
â”œâ”€â”€ manifest.json        # Skill metadata & trigger config
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ router.py        # URL â†’ Parser routing logic
â”‚   â”œâ”€â”€ storage.py       # Markdown file generation & saving
â”‚   â””â”€â”€ utils.py         # URL extraction & helper utilities
â””â”€â”€ parsers/
    â”œâ”€â”€ base.py          # Abstract base parser & ParseResult model
    â”œâ”€â”€ generic.py       # Generic article/blog parser (Trafilatura)
    â”œâ”€â”€ twitter.py       # Twitter/X parser (FxTwitter + Nitter)
    â”œâ”€â”€ reddit.py        # Reddit parser (.json API)
    â””â”€â”€ youtube.py       # YouTube transcript parser
```

### Router Strategy

```
URL detected â†’ is Twitter/X?  â†’ FxTwitter API â†’ Nitter fallback
             â†’ is Reddit?     â†’ .json suffix API
             â†’ is YouTube?    â†’ youtube-transcript-api
             â†’ otherwise      â†’ Trafilatura (generic)
```

---

## ğŸ”§ Configuration

DeepReader uses sensible defaults out of the box. Configuration can be customized via environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `DEEPREEDER_MEMORY_PATH` | `../../memory/inbox/` | Where to save ingested content (absolute path, or relative to repo root) |
| `DEEPREEDER_LOG_LEVEL` | `INFO` | Logging verbosity (`DEBUG`, `INFO`, `WARNING`, `ERROR`) |

---

## ğŸ’¡ Why DeepReader?

| Feature | DeepReader | Manual scraping | Browser tools |
|---------|-----------|----------------|---------------|
| **Trigger** | Automatic on URL | Manual code | Manual action |
| **Twitter/X** | âœ… Full support | âŒ Blocked | âš ï¸ Partial |
| **Reddit threads** | âœ… + comments | âš ï¸ Complex | âš ï¸ Slow |
| **YouTube transcripts** | âœ… Built-in | âŒ Separate tool | âŒ Not available |
| **API keys needed** | âŒ None | âœ… Often | âœ… Sometimes |
| **Output format** | Clean Markdown | Raw HTML | Screenshots |
| **Memory integration** | âœ… Auto-save | âŒ Manual | âŒ Manual |

---

## ğŸ™ Credits

- **[FxTwitter / FixTweet](https://github.com/FxEmbed/FxEmbed)** â€” Public API for fetching Twitter/X content
- **[x-tweet-fetcher](https://github.com/ythx-101/x-tweet-fetcher)** â€” Inspiration for the FxTwitter integration approach
- **[Trafilatura](https://trafilatura.readthedocs.io/)** â€” Robust web content extraction
- **[youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)** â€” YouTube transcript fetching
- **[notebooklm-py](https://github.com/teng-lin/notebooklm-py)** â€” Google NotebookLM integration for audio generation

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-parser`)
3. Commit your changes (`git commit -m 'Add amazing parser'`)
4. Push to the branch (`git push origin feature/amazing-parser`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  Built with ğŸ¦ by <a href="https://github.com/astonysh">OpenClaw</a>
</p>
