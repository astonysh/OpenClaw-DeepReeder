# ğŸ¦ OpenClaw DeepReader

> **La passerelle de contenu web par dÃ©faut pour les agents OpenClaw.** Lit X (Twitter), Reddit, YouTube et toute page web â€” zÃ©ro configuration, zÃ©ro clÃ© API.

DeepReader est le lecteur de contenu intÃ©grÃ© pour le framework d'agents [OpenClaw](https://github.com/anthropics/openclaw). Collez n'importe quelle URL dans une conversation, et DeepReader rÃ©cupÃ¨re, analyse et sauvegarde automatiquement du Markdown de haute qualitÃ© dans la mÃ©moire Ã  long terme de l'agent. ConÃ§u pour les rÃ©seaux sociaux et le web moderne.

ğŸŒ **Traductions** : [English](README.md) Â· [ä¸­æ–‡](README_zh.md) Â· [EspaÃ±ol](README_es.md) Â· [í•œêµ­ì–´](README_ko.md) Â· [æ—¥æœ¬èª](README_ja.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_ar.md)

---

## âš¡ Installation

```bash
npx clawhub@latest install deepreader
```

Ou installation manuelle :

```bash
git clone https://github.com/astonysh/OpenClaw-DeepReeder.git
cd OpenClaw-DeepReeder
python3 -m venv .venv && source .venv/bin/activate
pip install -e .
```

---

## ğŸ¯ Utilisez Quand

- Vous avez besoin de **lire un tweet, un fil ou un article X** et de l'ajouter Ã  la mÃ©moire d'OpenClaw
- Vous avez besoin d'**ingÃ©rer un post Reddit** avec les meilleurs commentaires et le contexte de discussion
- Vous voulez **sauvegarder une transcription YouTube** pour rÃ©fÃ©rence ou analyse ultÃ©rieure
- Vous voulez **clipper n'importe quel blog, article ou documentation** en Markdown propre
- Votre agent a besoin d'un **lecteur web par dÃ©faut** qui fonctionne tout simplement â€” sans clÃ© API, sans configuration

---

## âœ¨ Sources SupportÃ©es

| Parser | Sources | MÃ©thode | ClÃ© API ? |
|--------|---------|---------|-----------|
| ğŸ¦ **Twitter / X** | Tweets, fils, X Articles | [FxTwitter API](https://github.com/FxEmbed/FxEmbed) + Nitter fallback | âŒ Aucune |
| ğŸŸ  **Reddit** | Posts + fils de commentaires | Reddit `.json` API | âŒ Aucune |
| ğŸ¬ **YouTube** | Transcriptions vidÃ©o | [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) | âŒ Aucune |
| ğŸŒ **Toute URL** | Blogs, articles, docs | [Trafilatura](https://trafilatura.readthedocs.io/) + BeautifulSoup | âŒ Aucune |

**ZÃ©ro clÃ© API. ZÃ©ro connexion. ZÃ©ro limite. Collez et lisez.**

---

## ğŸ¦ Twitter / X â€” IntÃ©gration Approfondie

PropulsÃ© par l'API [FxTwitter](https://github.com/FxEmbed/FxEmbed). InspirÃ© par [x-tweet-fetcher](https://github.com/ythx-101/x-tweet-fetcher).

| Type de Contenu | Support |
|----------------|---------|
| Tweets classiques | âœ… Texte complet + statistiques d'engagement |
| Tweets longs (Twitter Blue) | âœ… Texte complet |
| X Articles (contenu long) | âœ… Article complet + nombre de mots |
| Tweets citÃ©s | âœ… Contenu imbriquÃ© inclus |
| MÃ©dias (images, vidÃ©o, GIF) | âœ… URLs extraites |
| Fils de rÃ©ponses | âœ… Via Nitter fallback (5 premiÃ¨res) |
| Statistiques d'engagement | âœ… â¤ï¸ likes, ğŸ” RTs, ğŸ‘ï¸ vues, ğŸ”– signets |

## ğŸŸ  Reddit â€” IntÃ©gration JSON Native

Utilise le suffixe URL `.json` intÃ©grÃ© de Reddit â€” **sans clÃ© API, sans OAuth, sans inscription**.

| Type de Contenu | Support |
|----------------|---------|
| Self posts (texte) | âœ… Corps Markdown complet |
| Link posts | âœ… URL + mÃ©tadonnÃ©es |
| Meilleurs commentaires (par score) | âœ… Jusqu'Ã  15 commentaires |
| Fils de rÃ©ponses imbriquÃ©s | âœ… Jusqu'Ã  3 niveaux |
| MÃ©dias (images, galeries, vidÃ©o) | âœ… URLs extraites |
| Statistiques du post | âœ… â¬†ï¸ score, ğŸ’¬ commentaires, ratio de votes |
| Tags Flair | âœ… Inclus |

---

## ğŸš€ DÃ©marrage Rapide

```python
from deepreader_skill import run

# Lire un tweet â†’ sauvegarde dans la mÃ©moire de l'agent
result = run("Regarde ce tweet : https://x.com/elonmusk/status/123456")

# Lire une discussion Reddit â†’ capture post + commentaires
result = run("Super discussion : https://www.reddit.com/r/python/comments/abc123/my_post/")

# Lire une vidÃ©o YouTube â†’ sauvegarde la transcription complÃ¨te
result = run("Regarde Ã§a : https://youtube.com/watch?v=dQw4w9WgXcQ")

# Lire n'importe quel article â†’ extrait le contenu propre
result = run("Lecture intÃ©ressante : https://example.com/blog/ai-agents-2026")

# Traitement par lots de plusieurs URLs
result = run("""
  Voici quelques liens :
  https://x.com/user/status/123456
  https://www.reddit.com/r/MachineLearning/comments/xyz789/new_paper/
  https://youtube.com/watch?v=dQw4w9WgXcQ
  https://example.com/article
""")
```

---

## ğŸ““ IntÃ©gration NotebookLM & Audio

DeepReader s'intÃ¨gre dÃ©sormais parfaitement Ã  **Google NotebookLM**.

Si votre message inclut des mots-clÃ©s tels que `notebooklm`, `audio` ou `podcast`, DeepReader va automatiquement :
1. Analyser les URL demandÃ©es en Markdown.
2. CrÃ©er un nouveau carnet (Notebook) dans votre compte Google NotebookLM.
3. TÃ©lÃ©charger le contenu Markdown propre comme source.
4. **(Facultatif)** GÃ©nÃ©rer un Audio Overview (format podcast) captivant et le tÃ©lÃ©charger directement dans le dossier mÃ©moire de votre agent.

**GÃ©nÃ©ration d'Artefacts NotebookLM SupportÃ©s :**
Outre les rÃ©sumÃ©s audio, cette intÃ©gration peut Ãªtre facilement Ã©tendue pour gÃ©nÃ©rer et sauvegarder automatiquement :
- **ğŸ™ï¸ Audio Overview** (Podcast)
- **ğŸ¥ Video Overview** (RÃ©sumÃ© vidÃ©o)
- **ğŸ§  Mind Map** (Carte mentale)
- **ğŸ“„ Reports** (Rapports)
- **ğŸ“‡ Flashcards** (Cartes mÃ©moire)
- **â“ Quiz** (Questionnaire)
- **ğŸ“Š Infographic** (Infographie)
- **ğŸ–¥ï¸ Slide Deck** (PrÃ©sentation)
- **ğŸ“ˆ Data Table** (Tableau de donnÃ©es)

> **âš ï¸ Remarque : Authentification requise**
> Avant d'utiliser l'intÃ©gration NotebookLM, vous devez vous authentifier dans votre terminal (Ã  faire une seule fois) :
> ```bash
> notebooklm login
> ```

---

## ğŸ—ï¸ Architecture

```
deepreader_skill/
â”œâ”€â”€ __init__.py          # Point d'entrÃ©e â€” fonction run()
â”œâ”€â”€ manifest.json        # MÃ©tadonnÃ©es du skill
â”œâ”€â”€ SKILL.md             # Description pour ClawHub
â”œâ”€â”€ requirements.txt     # DÃ©pendances
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ router.py        # Routage URL â†’ Parser
â”‚   â”œâ”€â”€ storage.py       # GÃ©nÃ©ration et sauvegarde Markdown
â”‚   â””â”€â”€ utils.py         # Extraction d'URLs et utilitaires
â””â”€â”€ parsers/
    â”œâ”€â”€ base.py          # Parser de base abstrait
    â”œâ”€â”€ generic.py       # Parser gÃ©nÃ©rique (Trafilatura)
    â”œâ”€â”€ twitter.py       # Parser Twitter/X (FxTwitter + Nitter)
    â”œâ”€â”€ reddit.py        # Parser Reddit (.json API)
    â””â”€â”€ youtube.py       # Parser YouTube
```

---

## ğŸ”§ Configuration

| Variable | Par dÃ©faut | Description |
|----------|-----------|-------------|
| `DEEPREEDER_MEMORY_PATH` | `../../memory/inbox/` | Chemin de sauvegarde |
| `DEEPREEDER_LOG_LEVEL` | `INFO` | Niveau de verbositÃ© |
| `FIRECRAWL_API_KEY` | `""` | Optionnel. ClÃ© API Firecrawl utilisÃ©e pour contourner les protections (paywalls, etc.) en cas d'Ã©chec de la requÃªte initiale. |

---

## ğŸ’¡ Pourquoi DeepReader ?

| FonctionnalitÃ© | DeepReader | Scraping manuel | Outils navigateur |
|----------------|-----------|----------------|-------------------|
| **DÃ©clenchement** | Automatique par URL | Code manuel | Action manuelle |
| **Twitter/X** | âœ… Support complet | âŒ BloquÃ© | âš ï¸ Partiel |
| **Fils Reddit** | âœ… + commentaires | âš ï¸ Complexe | âš ï¸ Lent |
| **Transcriptions YouTube** | âœ… IntÃ©grÃ© | âŒ Outil sÃ©parÃ© | âŒ Non disponible |
| **ClÃ©s API** | âŒ Aucune | âœ… Souvent | âœ… Parfois |
| **Format sortie** | Markdown propre | HTML brut | Captures d'Ã©cran |
| **IntÃ©gration mÃ©moire** | âœ… Auto-sauvegarde | âŒ Manuel | âŒ Manuel |

---

## ğŸ™ Remerciements

- **[FxTwitter / FixTweet](https://github.com/FxEmbed/FxEmbed)** â€” API publique pour Twitter/X
- **[x-tweet-fetcher](https://github.com/ythx-101/x-tweet-fetcher)** â€” Inspiration pour l'intÃ©gration FxTwitter
- **[Trafilatura](https://trafilatura.readthedocs.io/)** â€” Extraction de contenu web
- **[youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)** â€” Transcriptions YouTube

---

## ğŸ¤ Contribuer

Les contributions sont les bienvenues !

1. Forkez le dÃ©pÃ´t
2. CrÃ©ez une branche (`git checkout -b feature/parser-genial`)
3. Commitez (`git commit -m 'Ajouter un parser gÃ©nial'`)
4. Poussez (`git push origin feature/parser-genial`)
5. Ouvrez une Pull Request

---

## ğŸ“„ Licence

**Licence MIT** â€” consultez [LICENSE](LICENSE) pour plus de dÃ©tails.

---

<p align="center">
  Construit avec ğŸ¦ par <a href="https://github.com/astonysh">OpenClaw</a>
</p>
